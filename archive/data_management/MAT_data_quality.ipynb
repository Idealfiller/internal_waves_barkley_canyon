{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with MAT files\n",
    "\n",
    "Load and display information from MAT files. Plot velocities, correlation strength, and echo intensity to check data quality. Find threshold depths for good data quality, based on binned values of correlation and intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     20
    ]
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import cmath\n",
    "from datetime import datetime\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as pldates\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy.signal as sig\n",
    "import scipy.integrate as integ\n",
    "import scipy.interpolate as interp\n",
    "import pandas as pd\n",
    "import seawater as sea\n",
    "from scipy.stats import chi2\n",
    "from scipy.io import loadmat\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "for i in range(2):\n",
    "    %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# load .mat file and display info\n",
    "\n",
    "ds = loadmat('../../../Data/Raw/Axis75_Mar1_2014/Axis75_Mar1_2014_mat_Feb20.mat')\n",
    "da = ds['adcp']                                   # adcp data\n",
    "du = da['u'][0,0]                                 # velocity data\n",
    "dt = da['time'][0,0][0]                           # time data\n",
    "dd = np.mean(da['depth'][0,0])-da['range'][0,0]   # depths\n",
    "print('Shape:',np.shape(da['corr'][0,0]))         # display shape of data\n",
    "print('Field names:',da.dtype.descr)              # display field names\n",
    "#print('------------')\n",
    "#print(ds['units']['time'])                       # display units of selected variable\n",
    "#print(da.dtype.names)                            # display field names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plot velocity data\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "im = ax.pcolormesh(dt, -dd[0], du, rasterized=True, cmap='RdBu_r', vmin=-0.20, vmax=0.20)\n",
    "cbar = fig.colorbar(im, ax=ax, fraction=0.05, pad=0.01, aspect=40, extend='both')\n",
    "ax.set_ylim(-904,-696)\n",
    "cbar.set_label('Velocity [m/s]')\n",
    "ax.set_xlabel('March 1, 2014 (raw)')\n",
    "ax.set_ylabel('Depth [m]')\n",
    "ax.set_title('Velocity data (MAT)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dd[0][23])\n",
    "var800 = np.nanvar(du[23])\n",
    "print(var800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plot correlation strength\n",
    "\n",
    "fig,((ax0,ax1),(ax2,ax3)) = plt.subplots(2,2,figsize=(10,4))\n",
    "plt.subplots_adjust(hspace=0,wspace=0)\n",
    "vmin=60\n",
    "vmax=140\n",
    "cmap='gnuplot'\n",
    "im0 = ax0.pcolormesh(dt, -dd[0], da['corr'][0,0][0,:,:], rasterized=True, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "im1 = ax1.pcolormesh(dt, -dd[0], da['corr'][0,0][1,:,:], rasterized=True, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "cbar1 = fig.colorbar(im1, ax=ax1, fraction=0.05, pad=0.01, aspect=40, extend='both')\n",
    "im2 = ax2.pcolormesh(dt, -dd[0], da['corr'][0,0][2,:,:], rasterized=True, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "im3 = ax3.pcolormesh(dt, -dd[0], da['corr'][0,0][3,:,:], rasterized=True, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "cbar3 = fig.colorbar(im3, ax=ax3, fraction=0.05, pad=0.01, aspect=40, extend='both')\n",
    "cbar1.set_label('Counts [#]')\n",
    "cbar3.set_label('Counts [#]')\n",
    "ax2.set_xlabel('March 1, 2014')\n",
    "ax3.set_xlabel('Time [UTC]')\n",
    "ax0.set_ylabel('Depth [m]')\n",
    "ax2.set_ylabel('Depth [m]')\n",
    "fig.suptitle('Correlation strength (new data)',y=1)\n",
    "ax0.set_title('Beam 1')\n",
    "ax1.set_title('Beam 2')\n",
    "ax2.set_title('Beam 3')\n",
    "ax3.set_title('Beam 4')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plot echo intensity\n",
    "\n",
    "fig,((ax0,ax1),(ax2,ax3)) = plt.subplots(2,2,figsize=(10,4))\n",
    "plt.subplots_adjust(hspace=0,wspace=0)\n",
    "vmin=50\n",
    "vmax=120\n",
    "cmap='gnuplot'\n",
    "im0 = ax0.pcolormesh(dt, -dd[0], da['intens'][0,0][0,:,:], rasterized=True, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "im1 = ax1.pcolormesh(dt, -dd[0], da['intens'][0,0][1,:,:], rasterized=True, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "cbar1 = fig.colorbar(im1, ax=ax1, fraction=0.05, pad=0.01, aspect=40, extend='both')\n",
    "im2 = ax2.pcolormesh(dt, -dd[0], da['intens'][0,0][2,:,:], rasterized=True, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "im3 = ax3.pcolormesh(dt, -dd[0], da['intens'][0,0][3,:,:], rasterized=True, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "cbar3 = fig.colorbar(im3, ax=ax3, fraction=0.05, pad=0.01, aspect=40, extend='both')\n",
    "cbar1.set_label('Counts [#]')\n",
    "cbar3.set_label('Counts [#]')\n",
    "ax2.set_xlabel('March 1, 2014')\n",
    "ax3.set_xlabel('Time [UTC]')\n",
    "ax0.set_ylabel('Depth [m]')\n",
    "ax2.set_ylabel('Depth [m]')\n",
    "fig.suptitle('Return signal strength intensity (new data)',y=1)\n",
    "ax0.set_title('Beam 1')\n",
    "ax1.set_title('Beam 2')\n",
    "ax2.set_title('Beam 3')\n",
    "ax3.set_title('Beam 4')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process to average correlation and intensity into 20 ping bins\n",
    "\n",
    "pings = 20                                            # number of pings for bins\n",
    "time_len = len(dt)                                    # length of time axis\n",
    "t = np.arange(0,time_len,pings)                       # indices of the time axis, in steps = # of pings\n",
    "t_len = len(t)                                        # length of time indice array\n",
    "d_len = len(dd[0])                                    # length of depth array\n",
    "d = np.arange(0,d_len,1)                              # indices of the depth axis\n",
    "dc = da['corr'][0,0]                                  # correlation matrix from MAT data\n",
    "di = da['intens'][0,0]                                # intensity matrix from MAT data\n",
    "\n",
    "corr0_avg = np.empty([d_len,t_len])                   # empty array for binned correlation values\n",
    "corr1_avg = np.empty([d_len,t_len])                   \n",
    "corr2_avg = np.empty([d_len,t_len])                 \n",
    "corr3_avg = np.empty([d_len,t_len])                   \n",
    "intens0_avg = np.empty([d_len,t_len])                 # empty array for binned intensity values\n",
    "intens1_avg = np.empty([d_len,t_len])                \n",
    "intens2_avg = np.empty([d_len,t_len])                 \n",
    "intens3_avg = np.empty([d_len,t_len])                \n",
    "\n",
    "count = 0                                             # keeps track of binned time index\n",
    "for i in t:                                           # loop to group time axis into bins\n",
    "    if i <= t[-1]:                                    # avoids the final time index\n",
    "        t_range = dt[i:i+(pings-1)]                   # time index range for # of pings\n",
    "        corr0_temp = np.empty(d_len)                  # temporary array for averaging\n",
    "        corr1_temp = np.empty(d_len)                  \n",
    "        corr2_temp = np.empty(d_len)                  \n",
    "        corr3_temp = np.empty(d_len)                  \n",
    "        intens0_temp = np.empty(d_len)                \n",
    "        intens1_temp = np.empty(d_len)                \n",
    "        intens2_temp = np.empty(d_len)                \n",
    "        intens3_temp = np.empty(d_len)                \n",
    "        for j in d:                                             # need to average at each depth\n",
    "            corr0_temp[j] = np.nanmean(dc[0,j,i:i+(pings-1)])   # average values over bin times at each depth\n",
    "            corr1_temp[j] = np.nanmean(dc[1,j,i:i+(pings-1)])  \n",
    "            corr2_temp[j] = np.nanmean(dc[2,j,i:i+(pings-1)])  \n",
    "            corr3_temp[j] = np.nanmean(dc[3,j,i:i+(pings-1)])  \n",
    "            intens0_temp[j] = np.nanmean(di[0,j,i:i+(pings-1)])  \n",
    "            intens1_temp[j] = np.nanmean(di[1,j,i:i+(pings-1)])  \n",
    "            intens2_temp[j] = np.nanmean(di[2,j,i:i+(pings-1)])  \n",
    "            intens3_temp[j] = np.nanmean(di[3,j,i:i+(pings-1)])  \n",
    "        corr0_avg[:,count] = corr0_temp                         # set averaged depths to binned time index\n",
    "        corr1_avg[:,count] = corr1_temp               \n",
    "        corr2_avg[:,count] = corr2_temp               \n",
    "        corr3_avg[:,count] = corr3_temp               \n",
    "        intens0_avg[:,count] = intens0_temp               \n",
    "        intens1_avg[:,count] = intens1_temp               \n",
    "        intens2_avg[:,count] = intens2_temp               \n",
    "        intens3_avg[:,count] = intens3_temp          \n",
    "    count += 1                                                  # move to next binned time index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# process to determine threshold depths\n",
    "\n",
    "corr_thres = 100                                                # set correlation threshold\n",
    "intens_thres = 60                                               # set intensity threshold\n",
    "corr0_eval = np.empty(t_len)                                    # empty arrays for evaluated depths\n",
    "corr1_eval = np.empty(t_len)\n",
    "corr2_eval = np.empty(t_len)\n",
    "corr3_eval = np.empty(t_len)\n",
    "intens0_eval = np.empty(t_len)\n",
    "intens1_eval = np.empty(t_len)\n",
    "intens2_eval = np.empty(t_len)\n",
    "intens3_eval = np.empty(t_len)\n",
    "\n",
    "for i in range(t_len):                                          # loops to find threshold depths at each ping bin\n",
    "    for j in d:                                                 # check each depth\n",
    "        if corr0_avg[j,i] <= corr_thres:                        # when value falls below threshold\n",
    "            corr0_eval[i] = dd[0][j]                            # set this depth for this ping bin\n",
    "            break                                               # break to next beam\n",
    "        else:                                                   # if doesn't meet threshold, set NaN\n",
    "            corr0_eval[i] = np.nan\n",
    "        continue\n",
    "    for j in d:\n",
    "        if corr1_avg[j,i] <= corr_thres:\n",
    "            corr1_eval[i] = dd[0][j]\n",
    "            break\n",
    "        else:\n",
    "            corr1_eval[i] = np.nan\n",
    "        continue\n",
    "    for j in d:\n",
    "        if corr2_avg[j,i] <= corr_thres:\n",
    "            corr2_eval[i] = dd[0][j]\n",
    "            break\n",
    "        else:\n",
    "            corr2_eval[i] = np.nan\n",
    "        continue\n",
    "    for j in d:\n",
    "        if corr3_avg[j,i] <= corr_thres:\n",
    "            corr3_eval[i] = dd[0][j]\n",
    "            break\n",
    "        else:\n",
    "            corr3_eval[i] = np.nan\n",
    "        continue\n",
    "        \n",
    "    for j in d:\n",
    "        if intens0_avg[j,i] <= intens_thres:\n",
    "            intens0_eval[i] = dd[0][j]\n",
    "            break\n",
    "        else:\n",
    "            intens0_eval[i] = np.nan\n",
    "        continue\n",
    "    for j in d:\n",
    "        if intens1_avg[j,i] <= intens_thres:\n",
    "            intens1_eval[i] = dd[0][j]\n",
    "            break\n",
    "        else:\n",
    "            intens1_eval[i] = np.nan\n",
    "        continue\n",
    "    for j in d:\n",
    "        if intens2_avg[j,i] <= intens_thres:\n",
    "            intens2_eval[i] = dd[0][j]\n",
    "            break\n",
    "        else:\n",
    "            intens2_eval[i] = np.nan\n",
    "        continue\n",
    "    for j in d:\n",
    "        if intens3_avg[j,i] <= intens_thres:\n",
    "            intens3_eval[i] = dd[0][j]\n",
    "            break\n",
    "        else:\n",
    "            intens3_eval[i] = np.nan\n",
    "        continue\n",
    "        \n",
    "corr0_depth = int(np.nanmean(corr0_eval))                                 # find beam threshold depth\n",
    "corr1_depth = int(np.nanmean(corr1_eval))\n",
    "corr2_depth = int(np.nanmean(corr2_eval))\n",
    "corr3_depth = int(np.nanmean(corr3_eval))\n",
    "corr_all = np.nanmean([corr0_depth,corr1_depth,corr2_depth,corr3_depth])  # find average threshold depth\n",
    "intens0_depth = int(np.nanmean(intens0_eval))\n",
    "intens1_depth = int(np.nanmean(intens1_eval))\n",
    "intens2_depth = int(np.nanmean(intens2_eval))\n",
    "intens3_depth = int(np.nanmean(intens3_eval))\n",
    "intens_all = np.nanmean([intens0_depth,intens1_depth,intens2_depth,intens3_depth])\n",
    "\n",
    "print('For this time range, beam 0 correlation falls below',corr_thres,'counts at an average depth of',-corr0_depth,'m.')\n",
    "print('For this time range, beam 1 correlation falls below',corr_thres,'counts at an average depth of',-corr1_depth,'m.')\n",
    "print('For this time range, beam 2 correlation falls below',corr_thres,'counts at an average depth of',-corr2_depth,'m.')\n",
    "print('For this time range, beam 3 correlation falls below',corr_thres,'counts at an average depth of',-corr3_depth,'m.')\n",
    "print('Average correlation threshold depth:',-corr_all,'m.')\n",
    "print('--------------------')\n",
    "print('For this time range, beam 0 intensity falls below',intens_thres,'counts at an average depth of',-intens0_depth,'m.')\n",
    "print('For this time range, beam 1 intensity falls below',intens_thres,'counts at an average depth of',-intens1_depth,'m.')\n",
    "print('For this time range, beam 2 intensity falls below',intens_thres,'counts at an average depth of',-intens2_depth,'m.')\n",
    "print('For this time range, beam 3 intensity falls below',intens_thres,'counts at an average depth of',-intens3_depth,'m.')\n",
    "print('Average intensity threshold depth:',-intens_all,'m.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
